{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    GAME_DATE      MATCHUP home_away     TEAM_ID       TEAM_NAME  \\\n",
      "0  2024-02-28  IND vs. NOP      Home  1610612754  Indiana Pacers   \n",
      "1  2024-02-28  DEN vs. SAC      Home  1610612743  Denver Nuggets   \n",
      "2  2024-02-28    SAC @ DEN      Away  1610612758  Denver Nuggets   \n",
      "3  2024-02-28  CHI vs. CLE      Home  1610612741   Chicago Bulls   \n",
      "4  2024-02-28    CLE @ CHI      Away  1610612739   Chicago Bulls   \n",
      "\n",
      "          OPPOSING_TEAM  \n",
      "0  New Orleans Pelicans  \n",
      "1      Sacramento Kings  \n",
      "2      Sacramento Kings  \n",
      "3   Cleveland Cavaliers  \n",
      "4   Cleveland Cavaliers  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_23532\\3454788115.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  upcoming_games.sort_values(by='DATE', inplace=True)\n",
      "C:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_23532\\3454788115.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  upcoming_games['GAME_DATE'] = upcoming_games['DATE'].dt.strftime('%Y-%m-%d')\n",
      "C:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_23532\\3454788115.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  upcoming_games.rename(columns={'Home_Away': 'home_away'}, inplace=True)\n",
      "C:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_23532\\3454788115.py:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'New Orleans Pelicans' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  upcoming_games.at[index, 'OPPOSING_TEAM'] = away_team_full_name\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from nba_api.stats.static import teams\n",
    "\n",
    "def prepare_upcoming_games_data(season_games_csv):\n",
    "    # Load season games data\n",
    "    data = pd.read_csv(season_games_csv)\n",
    "    \n",
    "    # Process home and away data\n",
    "    home_data = data[['DATE', 'Start (ET)', 'Home/Neutral']].copy()\n",
    "    home_data['Home_Away'] = 'Home'\n",
    "    home_data['MATCHUP'] = home_data['Home/Neutral'] + ' vs. ' + data['Visitor/Neutral']\n",
    "    home_data.rename(columns={'Home/Neutral': 'Team'}, inplace=True)\n",
    "    home_data['WL_encoded'] = np.nan\n",
    "    \n",
    "    away_data = data[['DATE', 'Start (ET)', 'Visitor/Neutral']].copy()\n",
    "    away_data['Home_Away'] = 'Away'\n",
    "    away_data['MATCHUP'] = away_data['Visitor/Neutral'] + ' @ ' + home_data['Team']  # Adjusted to use '@' for away games\n",
    "    away_data.rename(columns={'Visitor/Neutral': 'Team'}, inplace=True)\n",
    "    away_data['WL_encoded'] = np.nan\n",
    "    \n",
    "    final_data = pd.concat([home_data, away_data], ignore_index=True)\n",
    "    final_data.sort_values(by=['DATE', 'Start (ET)', 'Home_Away'], inplace=True)\n",
    "    final_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Convert 'DATE' column to datetime format\n",
    "    final_data['DATE'] = pd.to_datetime(final_data['DATE'], format='%a, %b %d, %Y')\n",
    "    \n",
    "    # Get unique team information from the NBA API\n",
    "    teams_info = teams.get_teams()\n",
    "    teams_df = pd.DataFrame(teams_info)\n",
    "    teams_df.rename(columns={'id': 'TEAM_ID', 'full_name': 'TEAM_NAME', 'abbreviation': 'TEAM_ABBREVIATION'}, inplace=True)\n",
    "    \n",
    "    # Merge final_data with teams_df to include TEAM_ID and abbreviations\n",
    "    final_data = pd.merge(final_data, teams_df[['TEAM_NAME', 'TEAM_ID', 'TEAM_ABBREVIATION']], left_on='Team', right_on='TEAM_NAME', how='left')\n",
    "    \n",
    "    # Ensure all team names in MATCHUP are abbreviations\n",
    "    for index, row in final_data.iterrows():\n",
    "        for _, team_row in teams_df.iterrows():\n",
    "            final_data.at[index, 'MATCHUP'] = final_data.at[index, 'MATCHUP'].replace(team_row['TEAM_NAME'], team_row['TEAM_ABBREVIATION'])\n",
    "    \n",
    "    # Extract and filter for upcoming games\n",
    "    today = pd.Timestamp.now().floor('D')  # Normalize to avoid time part\n",
    "    week_out = today + timedelta(days=7)\n",
    "    upcoming_games = final_data[(final_data['DATE'] >= today) & (final_data['DATE'] <= week_out)]\n",
    "    upcoming_games.sort_values(by='DATE', inplace=True)\n",
    "    upcoming_games.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Format the 'DATE' column to match the example output's 'GAME_DATE' format\n",
    "    upcoming_games['GAME_DATE'] = upcoming_games['DATE'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Correct the column name for consistency\n",
    "    upcoming_games.rename(columns={'Home_Away': 'home_away'}, inplace=True)\n",
    "    \n",
    "    # Drop unnecessary columns and adjust to match the target dataset structure\n",
    "    upcoming_games = upcoming_games[['GAME_DATE', 'MATCHUP', 'home_away', 'TEAM_ID', 'TEAM_NAME']]\n",
    "    \n",
    "    # Create OPPOSING_TEAM column\n",
    "    upcoming_games['OPPOSING_TEAM'] = np.nan  # Placeholder for opposing team names\n",
    "    \n",
    "    # Populate TEAM_NAME and OPPOSING_TEAM with full names\n",
    "    for index, row in upcoming_games.iterrows():\n",
    "        home_team, away_team = row['MATCHUP'].split(' @ ') if row['home_away'] == 'Away' else row['MATCHUP'].split(' vs. ')\n",
    "        home_team_full_name = teams_df[teams_df['TEAM_ABBREVIATION'] == home_team]['TEAM_NAME'].values[0]\n",
    "        away_team_full_name = teams_df[teams_df['TEAM_ABBREVIATION'] == away_team]['TEAM_NAME'].values[0]\n",
    "        \n",
    "        if row['home_away'] == 'Home':\n",
    "            upcoming_games.at[index, 'TEAM_NAME'] = home_team_full_name\n",
    "            upcoming_games.at[index, 'OPPOSING_TEAM'] = away_team_full_name\n",
    "        else:\n",
    "            upcoming_games.at[index, 'TEAM_NAME'] = away_team_full_name\n",
    "            upcoming_games.at[index, 'OPPOSING_TEAM'] = home_team_full_name\n",
    "    \n",
    "    \n",
    "    return upcoming_games\n",
    "\n",
    "# Example usage\n",
    "season_games_csv = 'data/23_24_season_games.csv'\n",
    "upcoming_games_df = prepare_upcoming_games_data(season_games_csv)\n",
    "print(upcoming_games_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_24412\\311170071.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  upcoming_games.sort_values(by='DATE', inplace=True)\n",
      "C:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_24412\\311170071.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  upcoming_games['GAME_DATE'] = upcoming_games['DATE'].dt.strftime('%Y-%m-%d')\n",
      "C:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_24412\\311170071.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  upcoming_games.rename(columns={'Home_Away': 'home_away'}, inplace=True)\n",
      "C:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_24412\\311170071.py:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'New Orleans Pelicans' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  upcoming_games.at[index, 'OPPOSING_TEAM'] = away_team_full_name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SEASON_ID', 'Player_ID', 'Game_ID', 'GAME_DATE', 'MATCHUP', 'WL',\n",
      "       'MIN', 'FGM', 'FGA', 'FG_PCT', 'FG3M', 'FG3A', 'FG3_PCT', 'FTM', 'FTA',\n",
      "       'FT_PCT', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
      "       'PTS', 'PLUS_MINUS', 'VIDEO_AVAILABLE', 'PLAYER_NAME',\n",
      "       'TEAM_ABBREVIATION', 'OPPONENT_ABBREVIATION', 'TEAM_NAME',\n",
      "       'OPPONENT_NAME', 'TEAM_WIN_RATE', 'OPPONENT_WIN_RATE', 'home_away'],\n",
      "      dtype='object')\n",
      "Index(['GAME_DATE', 'MATCHUP', 'home_away', 'TEAM_ID', 'TEAM_NAME',\n",
      "       'OPPOSING_TEAM'],\n",
      "      dtype='object')\n",
      "      GAME_DATE      MATCHUP home_away     TEAM_ID       TEAM_NAME  \\\n",
      "0    2024-02-28  IND vs. NOP      Home  1610612754  Indiana Pacers   \n",
      "51   2024-02-28  IND vs. NOP      Home  1610612754  Indiana Pacers   \n",
      "106  2024-02-28  IND vs. NOP      Home  1610612754  Indiana Pacers   \n",
      "139  2024-02-28  IND vs. NOP      Home  1610612754  Indiana Pacers   \n",
      "191  2024-02-28  IND vs. NOP      Home  1610612754  Indiana Pacers   \n",
      "\n",
      "            OPPOSING_TEAM  Player_ID         PLAYER_NAME SEASON_ID  MIN  \n",
      "0    New Orleans Pelicans    1630174       Aaron Nesmith     22023  NaN  \n",
      "51   New Orleans Pelicans    1631097  Bennedict Mathurin     22023  NaN  \n",
      "106  New Orleans Pelicans    1628971         Bruce Brown     22023  NaN  \n",
      "139  New Orleans Pelicans    1627741         Buddy Hield     22023  NaN  \n",
      "191  New Orleans Pelicans    1626167        Myles Turner     22023  NaN  \n",
      "175\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from nba_api.stats.static import teams\n",
    "\n",
    "def prepare_upcoming_games_data(season_games_csv, player_game_logs_csv, expand_with_players=False):\n",
    "    # Load season games data\n",
    "    data = pd.read_csv(season_games_csv)\n",
    "    \n",
    "    # Process home and away data\n",
    "    home_data = data[['DATE', 'Start (ET)', 'Home/Neutral']].copy()\n",
    "    home_data['Home_Away'] = 'Home'\n",
    "    home_data['MATCHUP'] = home_data['Home/Neutral'] + ' vs. ' + data['Visitor/Neutral']\n",
    "    home_data.rename(columns={'Home/Neutral': 'Team'}, inplace=True)\n",
    "    home_data['WL_encoded'] = np.nan\n",
    "    \n",
    "    away_data = data[['DATE', 'Start (ET)', 'Visitor/Neutral']].copy()\n",
    "    away_data['Home_Away'] = 'Away'\n",
    "    away_data['MATCHUP'] = away_data['Visitor/Neutral'] + ' @ ' + home_data['Team']  # Adjusted to use '@' for away games\n",
    "    away_data.rename(columns={'Visitor/Neutral': 'Team'}, inplace=True)\n",
    "    away_data['WL_encoded'] = np.nan\n",
    "    \n",
    "    final_data = pd.concat([home_data, away_data], ignore_index=True)\n",
    "    final_data.sort_values(by=['DATE', 'Start (ET)', 'Home_Away'], inplace=True)\n",
    "    final_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Convert 'DATE' column to datetime format\n",
    "    final_data['DATE'] = pd.to_datetime(final_data['DATE'], format='%a, %b %d, %Y')\n",
    "    \n",
    "    # Get unique team information from the NBA API\n",
    "    teams_info = teams.get_teams()\n",
    "    teams_df = pd.DataFrame(teams_info)\n",
    "    teams_df.rename(columns={'id': 'TEAM_ID', 'full_name': 'TEAM_NAME', 'abbreviation': 'TEAM_ABBREVIATION'}, inplace=True)\n",
    "    \n",
    "    # Merge final_data with teams_df to include TEAM_ID and abbreviations\n",
    "    final_data = pd.merge(final_data, teams_df[['TEAM_NAME', 'TEAM_ID', 'TEAM_ABBREVIATION']], left_on='Team', right_on='TEAM_NAME', how='left')\n",
    "    \n",
    "    # Ensure all team names in MATCHUP are abbreviations\n",
    "    for index, row in final_data.iterrows():\n",
    "        for _, team_row in teams_df.iterrows():\n",
    "            final_data.at[index, 'MATCHUP'] = final_data.at[index, 'MATCHUP'].replace(team_row['TEAM_NAME'], team_row['TEAM_ABBREVIATION'])\n",
    "    \n",
    "    # Extract and filter for upcoming games\n",
    "    today = pd.Timestamp.now().floor('D')  # Normalize to avoid time part\n",
    "    week_out = today + timedelta(days=7)\n",
    "    upcoming_games = final_data[(final_data['DATE'] >= today) & (final_data['DATE'] <= week_out)]\n",
    "    upcoming_games.sort_values(by='DATE', inplace=True)\n",
    "    upcoming_games.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Format the 'DATE' column to match the example output's 'GAME_DATE' format\n",
    "    upcoming_games['GAME_DATE'] = upcoming_games['DATE'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Correct the column name for consistency\n",
    "    upcoming_games.rename(columns={'Home_Away': 'home_away'}, inplace=True)\n",
    "    \n",
    "    # Drop unnecessary columns and adjust to match the target dataset structure\n",
    "    upcoming_games = upcoming_games[['GAME_DATE', 'MATCHUP', 'home_away', 'TEAM_ID', 'TEAM_NAME']]\n",
    "    \n",
    "    # Create OPPOSING_TEAM column\n",
    "    upcoming_games['OPPOSING_TEAM'] = np.nan  # Placeholder for opposing team names\n",
    "    \n",
    "    # Populate TEAM_NAME and OPPOSING_TEAM with full names\n",
    "    for index, row in upcoming_games.iterrows():\n",
    "        home_team, away_team = row['MATCHUP'].split(' @ ') if row['home_away'] == 'Away' else row['MATCHUP'].split(' vs. ')\n",
    "        home_team_full_name = teams_df[teams_df['TEAM_ABBREVIATION'] == home_team]['TEAM_NAME'].values[0]\n",
    "        away_team_full_name = teams_df[teams_df['TEAM_ABBREVIATION'] == away_team]['TEAM_NAME'].values[0]\n",
    "        \n",
    "        if row['home_away'] == 'Home':\n",
    "            upcoming_games.at[index, 'TEAM_NAME'] = home_team_full_name\n",
    "            upcoming_games.at[index, 'OPPOSING_TEAM'] = away_team_full_name\n",
    "        else:\n",
    "            upcoming_games.at[index, 'TEAM_NAME'] = away_team_full_name\n",
    "            upcoming_games.at[index, 'OPPOSING_TEAM'] = home_team_full_name\n",
    "    \n",
    "    \n",
    "\n",
    "    # Load player game logs to use for fetching rosters\n",
    "    player_game_logs = pd.read_csv(player_game_logs_csv)\n",
    "    print(player_game_logs.columns)\n",
    "    print(upcoming_games.columns)\n",
    "    \n",
    "    if expand_with_players:\n",
    "        expanded_games_with_players = pd.DataFrame()\n",
    "\n",
    "        # Assuming player_game_logs_csv is correctly loaded into player_game_logs DataFrame\n",
    "        player_game_logs = pd.read_csv('data\\player_game_logs_winr.csv')\n",
    "\n",
    "        expanded_rows = []\n",
    "\n",
    "        for _, game in upcoming_games.iterrows():\n",
    "            team_name = game['TEAM_NAME']\n",
    "            team_players = player_game_logs[player_game_logs['TEAM_NAME'] == team_name]\n",
    "\n",
    "            for _, player in team_players.iterrows():\n",
    "                expanded_row = game.copy().to_dict()\n",
    "                expanded_row['Player_ID'] = player['Player_ID']\n",
    "                expanded_row['PLAYER_NAME'] = player['PLAYER_NAME']\n",
    "                expanded_rows.append(expanded_row)\n",
    "\n",
    "        expanded_games_with_players = pd.DataFrame(expanded_rows)\n",
    "\n",
    "        expanded_games_with_players = expanded_games_with_players.drop_duplicates(subset=['PLAYER_NAME'])\n",
    "\n",
    "\n",
    "        # After expanding games with players, adjust columns to match player_game_logs_winr structure\n",
    "        # Here you would set default values or transform columns as needed to match the structure\n",
    "        # For demonstration, let's set some columns to default values\n",
    "        expanded_games_with_players['SEASON_ID'] = '22023'\n",
    "        expanded_games_with_players['MIN'] = np.nan  # Just an example, adjust according to your data needs\n",
    "        \n",
    "        # Return the expanded DataFrame\n",
    "        return expanded_games_with_players\n",
    "\n",
    "\n",
    "    return upcoming_games\n",
    "\n",
    "# Example usage with file paths\n",
    "season_games_csv = 'data/23_24_season_games.csv'\n",
    "player_game_logs_csv = 'data/player_game_logs_winr.csv'\n",
    "upcoming_games = prepare_upcoming_games_data(season_games_csv, player_game_logs_csv, expand_with_players=True)\n",
    "print(upcoming_games.head())\n",
    "print(len(upcoming_games))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in concatenated dataset: 8811\n",
      "Latest date in previous games dataset: 2024-02-27 00:00:00\n",
      "Earliest date in upcoming games dataset: 2024-02-28 00:00:00\n",
      "Latest date in concatenated dataset: 2024-03-06 00:00:00\n",
      "  SEASON_ID  Player_ID     Game_ID  GAME_DATE      MATCHUP WL   MIN  FGM  \\\n",
      "0     22023     203484  22300061.0 2023-10-24  DEN vs. LAL  W  36.0  8.0   \n",
      "1     22023     203076  22300061.0 2023-10-24    LAL @ DEN  L  34.0  6.0   \n",
      "2     22023    1630559  22300061.0 2023-10-24    LAL @ DEN  L  31.0  4.0   \n",
      "3     22023     203952  22300062.0 2023-10-24  GSW vs. PHX  L  27.0  4.0   \n",
      "4     22023    1630228  22300062.0 2023-10-24  GSW vs. PHX  L  20.0  4.0   \n",
      "\n",
      "    FGA  FG_PCT  ...               PLAYER_NAME  TEAM_ABBREVIATION  \\\n",
      "0  12.0   0.667  ...  Kentavious Caldwell-Pope                DEN   \n",
      "1  17.0   0.353  ...             Anthony Davis                LAL   \n",
      "2  11.0   0.364  ...             Austin Reaves                LAL   \n",
      "3  12.0   0.333  ...            Andrew Wiggins                GSW   \n",
      "4   8.0   0.500  ...          Jonathan Kuminga                GSW   \n",
      "\n",
      "   OPPONENT_ABBREVIATION              TEAM_NAME       OPPONENT_NAME  \\\n",
      "0                    LAL         Denver Nuggets  Los Angeles Lakers   \n",
      "1                    DEN     Los Angeles Lakers      Denver Nuggets   \n",
      "2                    DEN     Los Angeles Lakers      Denver Nuggets   \n",
      "3                    PHX  Golden State Warriors        Phoenix Suns   \n",
      "4                    PHX  Golden State Warriors        Phoenix Suns   \n",
      "\n",
      "   TEAM_WIN_RATE  OPPONENT_WIN_RATE  home_away  TEAM_ID  OPPOSING_TEAM  \n",
      "0       0.600000           0.333333       Home      NaN            NaN  \n",
      "1       0.333333           0.600000       Away      NaN            NaN  \n",
      "2       0.333333           0.600000       Away      NaN            NaN  \n",
      "3       0.800000           0.800000       Home      NaN            NaN  \n",
      "4       0.800000           0.800000       Home      NaN            NaN  \n",
      "\n",
      "[5 rows x 37 columns]\n",
      "8811\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    data = pd.read_csv('data/player_game_logs_winr.csv')\n",
    "    data['GAME_DATE'] = pd.to_datetime(data['GAME_DATE'])\n",
    "    data.sort_values(by='GAME_DATE', inplace=True)\n",
    "    return data\n",
    "\n",
    "# Load the existing games data\n",
    "previous_games = load_data()\n",
    "\n",
    "# Ensure GAME_DATE is in datetime format for comparison\n",
    "upcoming_games['GAME_DATE'] = pd.to_datetime(upcoming_games['GAME_DATE'])\n",
    "\n",
    "# Filter out upcoming games that have dates already in previous games\n",
    "unique_upcoming_games = upcoming_games[~upcoming_games['GAME_DATE'].isin(previous_games['GAME_DATE'])]\n",
    "\n",
    "# Concatenate the unique upcoming games to the previous games dataset\n",
    "concatenated_data = pd.concat([previous_games, unique_upcoming_games], ignore_index=True)\n",
    "\n",
    "# Sort the concatenated data by GAME_DATE to maintain chronological order\n",
    "concatenated_data.sort_values(by='GAME_DATE', inplace=True)\n",
    "\n",
    "# Reset the index of the concatenated DataFrame\n",
    "concatenated_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Perform checks after concatenation\n",
    "print(\"Number of rows in concatenated dataset:\", len(concatenated_data))\n",
    "print(\"Latest date in previous games dataset:\", previous_games['GAME_DATE'].max())\n",
    "print(\"Earliest date in upcoming games dataset:\", unique_upcoming_games['GAME_DATE'].min())\n",
    "print(\"Latest date in concatenated dataset:\", concatenated_data['GAME_DATE'].max())\n",
    "\n",
    "# Example usage\n",
    "concat_data = concatenated_data\n",
    "print(concat_data.head())\n",
    "print(len(concat_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1610612737 1610612738 1610612739 1610612740 1610612741 1610612742\n",
      " 1610612743 1610612744 1610612745 1610612746 1610612747 1610612748\n",
      " 1610612749 1610612750 1610612751 1610612752 1610612753 1610612754\n",
      " 1610612755 1610612756 1610612757 1610612758 1610612759 1610612760\n",
      " 1610612761 1610612762 1610612763 1610612764 1610612765 1610612766]\n",
      "['Atlanta Hawks' 'Boston Celtics' 'Cleveland Cavaliers'\n",
      " 'New Orleans Pelicans' 'Chicago Bulls' 'Dallas Mavericks'\n",
      " 'Denver Nuggets' 'Golden State Warriors' 'Houston Rockets'\n",
      " 'Los Angeles Clippers' 'Los Angeles Lakers' 'Miami Heat'\n",
      " 'Milwaukee Bucks' 'Minnesota Timberwolves' 'Brooklyn Nets'\n",
      " 'New York Knicks' 'Orlando Magic' 'Indiana Pacers' 'Philadelphia 76ers'\n",
      " 'Phoenix Suns' 'Portland Trail Blazers' 'Sacramento Kings'\n",
      " 'San Antonio Spurs' 'Oklahoma City Thunder' 'Toronto Raptors' 'Utah Jazz'\n",
      " 'Memphis Grizzlies' 'Washington Wizards' 'Detroit Pistons'\n",
      " 'Charlotte Hornets']\n",
      "['ATL' 'BOS' 'CLE' 'NOP' 'CHI' 'DAL' 'DEN' 'GSW' 'HOU' 'LAC' 'LAL' 'MIA'\n",
      " 'MIL' 'MIN' 'BKN' 'NYK' 'ORL' 'IND' 'PHI' 'PHX' 'POR' 'SAC' 'SAS' 'OKC'\n",
      " 'TOR' 'UTA' 'MEM' 'WAS' 'DET' 'CHA']\n",
      "{'Atlanta Hawks': 'ATL', 'Boston Celtics': 'BOS', 'Cleveland Cavaliers': 'CLE', 'New Orleans Pelicans': 'NOP', 'Chicago Bulls': 'CHI', 'Dallas Mavericks': 'DAL', 'Denver Nuggets': 'DEN', 'Golden State Warriors': 'GSW', 'Houston Rockets': 'HOU', 'Los Angeles Clippers': 'LAC', 'Los Angeles Lakers': 'LAL', 'Miami Heat': 'MIA', 'Milwaukee Bucks': 'MIL', 'Minnesota Timberwolves': 'MIN', 'Brooklyn Nets': 'BKN', 'New York Knicks': 'NYK', 'Orlando Magic': 'ORL', 'Indiana Pacers': 'IND', 'Philadelphia 76ers': 'PHI', 'Phoenix Suns': 'PHX', 'Portland Trail Blazers': 'POR', 'Sacramento Kings': 'SAC', 'San Antonio Spurs': 'SAS', 'Oklahoma City Thunder': 'OKC', 'Toronto Raptors': 'TOR', 'Utah Jazz': 'UTA', 'Memphis Grizzlies': 'MEM', 'Washington Wizards': 'WAS', 'Detroit Pistons': 'DET', 'Charlotte Hornets': 'CHA'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you've already read in your df1\n",
    "unique_teams = pd.read_csv(r'C:\\Users\\ghadf\\OneDrive\\Desktop\\Data Analytics\\Python\\ML\\nba_w_l_prediction_models\\nba_analysis\\data\\team_ids.csv')\n",
    "\n",
    "# take only the first \n",
    "unique_teams = unique_teams.drop_duplicates(subset='TEAM_ID', keep='first')\n",
    "\n",
    "\n",
    "\n",
    "#change team name \"LA Clippers\" to \"Los Angeles Clippers\"\n",
    "unique_teams['TEAM_NAME'] = unique_teams['TEAM_NAME'].replace('LA Clippers', 'Los Angeles Clippers')\n",
    "\n",
    "# get unique values from team_id and season_id columns\n",
    "unique_team_ids = unique_teams['TEAM_ID'].unique()\n",
    "print(unique_team_ids)\n",
    "unique_team_names = unique_teams['TEAM_NAME'].unique()\n",
    "print(unique_team_names)\n",
    "unique_team_names = unique_teams['TEAM_ABBREVIATION'].unique()\n",
    "print(unique_team_names)\n",
    "\n",
    "#take only the columns team_id, team_name, season_id, and game_id\n",
    "\n",
    "#print(df1.head())\n",
    "\n",
    "# Assuming df1 has been read in and unique_teams has been created\n",
    "team_to_abbreviation = dict(zip(unique_teams['TEAM_NAME'], unique_teams['TEAM_ABBREVIATION']))\n",
    "\n",
    "print(team_to_abbreviation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1610612737, 1610612738, 1610612739, 1610612740, 1610612741, 1610612742, 1610612743, 1610612744, 1610612745, 1610612746, 1610612747, 1610612748, 1610612749, 1610612750, 1610612751, 1610612752, 1610612753, 1610612754, 1610612755, 1610612756, 1610612757, 1610612758, 1610612759, 1610612760, 1610612761, 1610612762, 1610612763, 1610612764, 1610612765, 1610612766"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "current_teams = [1610612739, 1610612737, 1610612738, 1610612740, 1610612741, 1610612742, 1610612743, 1610612744, 1610612745, 1610612746, 1610612747, 1610612748, 1610612749, 1610612750, 1610612751, 1610612752, 1610612753, 1610612754, 1610612755, 1610612756, 1610612757, 1610612758, 1610612759, 1610612760, 1610612761, 1610612762, 1610612763, 1610612764, 1610612765, 1610612766]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE             0\n",
      "Start (ET)       0\n",
      "Team             0\n",
      "Home_Away        0\n",
      "MATCHUP          0\n",
      "WL_encoded    2400\n",
      "dtype: int64\n",
      "TEAM_ID              0\n",
      "TEAM_NAME            0\n",
      "TEAM_ABBREVIATION    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>Start (ET)</th>\n",
       "      <th>Team</th>\n",
       "      <th>Home_Away</th>\n",
       "      <th>MATCHUP</th>\n",
       "      <th>WL_encoded</th>\n",
       "      <th>TEAM_ID</th>\n",
       "      <th>TEAM_NAME</th>\n",
       "      <th>TEAM_ABBREVIATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [DATE, Start (ET), Team, Home_Away, MATCHUP, WL_encoded, TEAM_ID, TEAM_NAME, TEAM_ABBREVIATION]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Convert 'Date' column to datetime format in final_data\n",
    "final_data['DATE'] = pd.to_datetime(final_data['DATE'])\n",
    "\n",
    "#count nan values\n",
    "print(final_data.isnull().sum())\n",
    "print(unique_teams.isnull().sum())\n",
    "\n",
    "# Merge final_data with unique_teams on the team names to get the TEAM_ID. Use 'left' to ensure final_data size isn't increased.\n",
    "final_data = final_data.merge(unique_teams, left_on='Team', right_on='TEAM_NAME', how='left')\n",
    "\n",
    "\n",
    "#count nan values\n",
    "final_data.isnull().sum()\n",
    "#view the team_id columns that have nan values\n",
    "final_data[final_data['TEAM_ID'].isnull()]\n",
    "\n",
    "#print(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1610612740\n",
      "1       1610612745\n",
      "2       1610612744\n",
      "3       1610612757\n",
      "4       1610612762\n",
      "           ...    \n",
      "2395    1610612741\n",
      "2396    1610612758\n",
      "2397    1610612762\n",
      "2398    1610612742\n",
      "2399    1610612759\n",
      "Name: TEAM_ID, Length: 2400, dtype: int64\n",
      "Index(['DATE', 'Start (ET)', 'Team', 'Home_Away', 'MATCHUP', 'WL_encoded',\n",
      "       'TEAM_ID', 'TEAM_NAME', 'TEAM_ABBREVIATION', 'TEAM_ID_OPP'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create a function to extract both teams from the matchup string\n",
    "def extract_teams(matchup):\n",
    "    # Split the string using 'vs.' as the delimiter\n",
    "    teams = matchup.split(' vs. ')\n",
    "    return teams\n",
    "\n",
    "# Apply the function to the 'MATCHUP' column\n",
    "final_data['Home_Team'], final_data['Away_Team'] = zip(*final_data['MATCHUP'].map(extract_teams))\n",
    "\n",
    "# Determine the opposing team for each row\n",
    "final_data['Opposing_Team'] = final_data.apply(lambda row: row['Away_Team'] if row['Team'] == row['Home_Team'] else row['Home_Team'], axis=1)\n",
    "\n",
    "# Create a mapping from the team name to the TEAM_ID using the unique_teams dataframe\n",
    "team_to_id = dict(zip(unique_teams['TEAM_NAME'], unique_teams['TEAM_ID']))\n",
    "\n",
    "# Map the opposing team name to its ID\n",
    "final_data['TEAM_ID_OPP'] = final_data['Opposing_Team'].map(team_to_id)\n",
    "\n",
    "# Drop the columns we created for the intermediate steps (optional)\n",
    "final_data.drop(columns=['Home_Team', 'Away_Team', 'Opposing_Team'], inplace=True)\n",
    "print(final_data['TEAM_ID'])\n",
    "print(final_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Home_Away                                         MATCHUP  WL_encoded  \\\n",
      "0         Away  Golden State Warriors vs. New Orleans Pelicans         NaN   \n",
      "1         Away      Portland Trail Blazers vs. Houston Rockets         NaN   \n",
      "2         Home  Golden State Warriors vs. New Orleans Pelicans         NaN   \n",
      "3         Home      Portland Trail Blazers vs. Houston Rockets         NaN   \n",
      "4         Away              Los Angeles Clippers vs. Utah Jazz         NaN   \n",
      "...        ...                                             ...         ...   \n",
      "2395      Home         Chicago Bulls vs. Oklahoma City Thunder         NaN   \n",
      "2396      Away                  Utah Jazz vs. Sacramento Kings         NaN   \n",
      "2397      Home                  Utah Jazz vs. Sacramento Kings         NaN   \n",
      "2398      Away          San Antonio Spurs vs. Dallas Mavericks         NaN   \n",
      "2399      Home          San Antonio Spurs vs. Dallas Mavericks         NaN   \n",
      "\n",
      "         TEAM_ID TEAM_ABBREVIATION  TEAM_ID_OPP  YEAR  MONTH  DAY  \n",
      "0     1610612740               NOP   1610612744  2024      4   12  \n",
      "1     1610612745               HOU   1610612757  2024      4   12  \n",
      "2     1610612744               GSW   1610612740  2024      4   12  \n",
      "3     1610612757               POR   1610612745  2024      4   12  \n",
      "4     1610612762               UTA   1610612746  2024      4   12  \n",
      "...          ...               ...          ...   ...    ...  ...  \n",
      "2395  1610612741               CHI   1610612760  2023     10   25  \n",
      "2396  1610612758               SAC   1610612762  2023     10   25  \n",
      "2397  1610612762               UTA   1610612758  2023     10   25  \n",
      "2398  1610612742               DAL   1610612759  2023     10   25  \n",
      "2399  1610612759               SAS   1610612742  2023     10   25  \n",
      "\n",
      "[2400 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Convert TEAM_ID and SEASON_ID to integers\n",
    "#final_data['TEAM_ID'] = final_data['TEAM_ID'].astype(int)\n",
    "#final_data['SEASON_ID'] = final_data['SEASON_ID'].astype(int)\n",
    "\n",
    "# If you want to convert them to strings after converting to integers, uncomment the following lines:\n",
    "# final_data['TEAM_ID'] = final_data['TEAM_ID'].astype(str)\n",
    "# final_data['SEASON_ID'] = final_data['SEASON_ID'].astype(str)\n",
    "\n",
    "# Drop 'TEAM_NAME' and 'Start (ET)' column as it's redundant\n",
    "final_data.drop(['TEAM_NAME', 'Start (ET)'], axis=1, inplace=True)\n",
    "\n",
    "#final_data['TEAM_ID'] = final_data['TEAM_ID'].astype('int64')\n",
    "\n",
    "# Assuming your dataframe is named 'final_data'\n",
    "final_data['YEAR'] = pd.to_datetime(final_data['DATE']).dt.year\n",
    "final_data['MONTH'] = pd.to_datetime(final_data['DATE']).dt.month\n",
    "final_data['DAY'] = pd.to_datetime(final_data['DATE']).dt.day\n",
    "\n",
    "# Dropping the original Date column and Team, Home_Away, Matchup columns\n",
    "final_data.drop(['DATE', 'Team'], axis=1, inplace=True)\n",
    "\n",
    "# add a matchup identifier column on when they happen on the same day\n",
    "#final_data['GAME_ID'] = final_data.groupby(['MATCHUP','YEAR', 'MONTH', 'DAY']).ngroup()\n",
    "\n",
    "print(final_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n",
      "  Home_Away      MATCHUP  WL_encoded     TEAM_ID TEAM_ABBREVIATION  \\\n",
      "0      Away    GSW @ NOP         NaN  1610612740               NOP   \n",
      "1      Away    POR @ HOU         NaN  1610612745               HOU   \n",
      "2      Home  GSW vs. NOP         NaN  1610612744               GSW   \n",
      "3      Home  POR vs. HOU         NaN  1610612757               POR   \n",
      "4      Away    LAC @ UTA         NaN  1610612762               UTA   \n",
      "\n",
      "   TEAM_ID_OPP  YEAR  MONTH  DAY MATCHUP_ID  \n",
      "0   1610612744  2024      4   12     GSWNOP  \n",
      "1   1610612757  2024      4   12     HOUPOR  \n",
      "2   1610612740  2024      4   12     GSWNOP  \n",
      "3   1610612745  2024      4   12     HOUPOR  \n",
      "4   1610612746  2024      4   12     LACUTA  \n",
      "2400\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def replace_team_names_with_abbreviations(row):\n",
    "    matchup_str = row['MATCHUP']\n",
    "    for team, abbreviation in team_to_abbreviation.items():\n",
    "        matchup_str = matchup_str.replace(team, abbreviation)\n",
    "    \n",
    "    # If the team is Away, replace \"vs.\" with \"@\"\n",
    "    if row['Home_Away'] == 'Away':\n",
    "        matchup_str = matchup_str.replace(\" vs. \", \" @ \")\n",
    "    return matchup_str\n",
    "\n",
    "\n",
    "final_data['MATCHUP'] = final_data.apply(replace_team_names_with_abbreviations, axis=1)\n",
    "#print(final_data)\n",
    "print(len(final_data))\n",
    "# Create the unique matchup ID\n",
    "def create_matchup_id(matchup):\n",
    "    # Split the teams based on \" vs. \" or \" @ \"\n",
    "    teams = matchup.split(' vs. ') if ' vs. ' in matchup else matchup.split(' @ ')\n",
    "    # Sort the teams alphabetically and concatenate\n",
    "    return ''.join(sorted(teams))\n",
    "\n",
    "final_data['MATCHUP_ID'] = final_data['MATCHUP'].apply(create_matchup_id)\n",
    "print(final_data.head())\n",
    "print(len(final_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Home_Away      MATCHUP  WL_encoded     TEAM_ID TEAM_ABBREVIATION  \\\n",
      "33      Home  WAS vs. PHI         NaN  1610612764               WAS   \n",
      "23      Home  DAL vs. OKC         NaN  1610612742               DAL   \n",
      "22      Away    DAL @ OKC         NaN  1610612760               OKC   \n",
      "21      Home  POR vs. NOP         NaN  1610612757               POR   \n",
      "20      Away    POR @ NOP         NaN  1610612740               NOP   \n",
      "..       ...          ...         ...         ...               ...   \n",
      "87      Home  UTA vs. LAL         NaN  1610612762               UTA   \n",
      "46      Away    POR @ MIN         NaN  1610612750               MIN   \n",
      "47      Home  POR vs. MIN         NaN  1610612757               POR   \n",
      "48      Away    MEM @ MIL         NaN  1610612749               MIL   \n",
      "49      Home  MEM vs. MIL         NaN  1610612763               MEM   \n",
      "\n",
      "    TEAM_ID_OPP  YEAR  MONTH  DAY MATCHUP_ID       Date  \n",
      "33   1610612755  2024      2   10     PHIWAS 2024-02-10  \n",
      "23   1610612760  2024      2   10     DALOKC 2024-02-10  \n",
      "22   1610612742  2024      2   10     DALOKC 2024-02-10  \n",
      "21   1610612740  2024      2   10     NOPPOR 2024-02-10  \n",
      "20   1610612757  2024      2   10     NOPPOR 2024-02-10  \n",
      "..          ...   ...    ...  ...        ...        ...  \n",
      "87   1610612747  2024      2   14     LALUTA 2024-02-14  \n",
      "46   1610612757  2024      2   15     MINPOR 2024-02-15  \n",
      "47   1610612750  2024      2   15     MINPOR 2024-02-15  \n",
      "48   1610612763  2024      2   15     MEMMIL 2024-02-15  \n",
      "49   1610612749  2024      2   15     MEMMIL 2024-02-15  \n",
      "\n",
      "[88 rows x 11 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghadf\\AppData\\Local\\Temp\\ipykernel_14844\\3973936647.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  upcoming_games.sort_values(by=['Date'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Taking the weeks worth of games\n",
    "# Create a Date column in the DataFrame\n",
    "final_data['Date'] = pd.to_datetime(final_data[['YEAR', 'MONTH', 'DAY']])\n",
    "\n",
    "#***making into a 1 row per game format***\n",
    "#get the first matchup_id per date\n",
    "#final_data = final_data.groupby(['MATCHUP_ID', 'Date']).first().reset_index()\n",
    "\n",
    "\n",
    "# Get today's date\n",
    "today = pd.Timestamp.today()-pd.Timedelta(days=1)\n",
    "\n",
    "# Get the date for one week from today\n",
    "week_out = today + pd.Timedelta(days=7)\n",
    "\n",
    "# Filter final_data for dates from today up to one week from now\n",
    "upcoming_games = final_data[(final_data['Date'] >= today) & (final_data['Date'] <= week_out)] # \n",
    "upcoming_games.reset_index(drop=True, inplace=True)\n",
    "#sort by date\n",
    "upcoming_games.sort_values(by=['Date'], inplace=True)\n",
    "print(upcoming_games)\n",
    "\n",
    "# Filter data for dates before tomorrow and save it as old_data\n",
    "today = pd.Timestamp.today()+pd.Timedelta(days=1)\n",
    "old_data = final_data#[final_data['Date'] <= today]\n",
    "\n",
    "#rename WL_encoded to ACTUAL_RESULT \n",
    "old_data.rename(columns={'WL_encoded': 'ACTUAL_RESULT'}, inplace=True)\n",
    "#add a prediction column full of nan\n",
    "#old_data['PREDICTION'] = np.nan\n",
    "#print(old_data)\n",
    "old_data.to_csv(r'C:\\Users\\ghadf\\OneDrive\\Desktop\\Data Analytics\\Python\\ML\\nba_w_l_prediction_models\\nba_analysis\\data\\23_24_season_games_past.csv', index=False)\n",
    "\n",
    "# Drop the 'Date' column\n",
    "#final_data.drop('Date', axis=1, inplace=True)\n",
    "#upcoming_games.drop('Date', axis=1, inplace=True)\n",
    "#old_data.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "#make predictions on 23_24_season_games_clean (upcoming games with previous season averages)\n",
    "#saving plan: make predictions on 23_24_season_games_clean (upcoming games with previous season averages)\n",
    "#1. get the weeks worth of upcoming games from today on so we can't predict on previous games\n",
    "#2. filter the old data for games including today (so we can add the predictions to this data and the actual results will get added the next day without changing the prediction based on new data)\n",
    "#3. merge the old data with the predictions data to save yesterday's results with the prediction attached\n",
    "#4. old_data will have today's games and the predictions will be input onto that data, \n",
    "# yesterday's games will have the actual results and will update just that because the model can only predict on today's games moving forward (upcoming_games)\n",
    "#5. the predictions will be saved to a csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1722\n",
      "Index(['TEAM_ID', 'Home_Away', 'MATCHUP_ID', 'PTS', 'FGM', 'FGA', 'FG3M',\n",
      "       'FG3A', 'FTM', 'FTA', 'AST', 'OREB', 'TOV', 'STL', 'BLK', 'REB', 'MIN',\n",
      "       'DREB', 'ORtg_Oliver', 'DRtg_Oliver', 'PTS_OPP', 'FGM_OPP', 'FGA_OPP',\n",
      "       'FG3M_OPP', 'FG3A_OPP', 'FTM_OPP', 'FTA_OPP', 'AST_OPP', 'OREB_OPP',\n",
      "       'DREB_OPP', 'TOV_OPP', 'STL_OPP', 'BLK_OPP', 'REB_OPP', 'MIN_OPP',\n",
      "       'ORtg_Oliver_OPP', 'DRtg_Oliver_OPP', 'PTS_PER_MIN', 'FG_PCT',\n",
      "       'FG3_PCT', 'FT_PCT', 'TS%', 'eFG%', 'AST%', 'Offensive_Possessions',\n",
      "       'ORtg', 'PER%', 'OFF_EFF', 'PTS_PER_MIN_OPP', 'FG_PCT_OPP',\n",
      "       'FG3_PCT_OPP', 'FT_PCT_OPP', 'TS%_OPP', 'eFG%_OPP', 'AST%_OPP',\n",
      "       'Defensive_Possessions', 'DRtg', 'DPER%', 'PTS_DIFF',\n",
      "       'PTS_PER_MIN_DIFF', 'FG_PCT_DIFF', 'FG3_PCT_DIFF', 'FT_PCT_DIFF',\n",
      "       'TS%_DIFF', 'eFG%_DIFF', 'AST%_DIFF', 'ORtg_DIFF', 'PER%_DIFF',\n",
      "       'ORtg_Oliver_DIFF', 'DRtg_Oliver_DIFF'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Read in the data for averages from X after it's dropped the columns we don't need and just before preprocessing through encoding\n",
    "#on a long short-term basis\n",
    "\n",
    "future_season_data_stats = pd.read_csv(r'C:\\Users\\ghadf\\OneDrive\\Desktop\\Data Analytics\\Python\\ML\\nba_w_l_prediction_models\\nba_analysis\\data\\future_season_data_stats.csv')\n",
    "#print(future_season_data_stats.head())\n",
    "#drop WL_encoded column\n",
    "#future_season_data_stats.drop(['WL_encoded', 'TEAM_ABBREVIATION', 'MATCHUP', 'YEAR', 'MONTH', 'DAY'], axis=1, inplace=True)\n",
    "\n",
    "#print(future_season_data_stats.head())\n",
    "print(len(future_season_data_stats))\n",
    "print(future_season_data_stats.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upcoming games=     Home_Away      MATCHUP  WL_encoded     TEAM_ID TEAM_ABBREVIATION  \\\n",
      "33      Home  WAS vs. PHI         NaN  1610612764               WAS   \n",
      "23      Home  DAL vs. OKC         NaN  1610612742               DAL   \n",
      "22      Away    DAL @ OKC         NaN  1610612760               OKC   \n",
      "21      Home  POR vs. NOP         NaN  1610612757               POR   \n",
      "20      Away    POR @ NOP         NaN  1610612740               NOP   \n",
      "\n",
      "    TEAM_ID_OPP  YEAR  MONTH  DAY MATCHUP_ID       Date  \n",
      "33   1610612755  2024      2   10     PHIWAS 2024-02-10  \n",
      "23   1610612760  2024      2   10     DALOKC 2024-02-10  \n",
      "22   1610612742  2024      2   10     DALOKC 2024-02-10  \n",
      "21   1610612740  2024      2   10     NOPPOR 2024-02-10  \n",
      "20   1610612757  2024      2   10     NOPPOR 2024-02-10  \n",
      "88\n",
      "future_season_data       TEAM_ID Home_Away MATCHUP_ID         PTS        FGM   FGA       FG3M  \\\n",
      "0  1610612737      Away     ATLBKN  111.500000  42.500000  92.0   9.000000   \n",
      "1  1610612737      Away     ATLBOS  109.500000  42.500000  98.0  12.750000   \n",
      "2  1610612737      Away     ATLCHA  124.333333  44.333333  92.0  10.333333   \n",
      "3  1610612737      Away     ATLCHI  111.500000  43.500000  85.5  10.000000   \n",
      "4  1610612737      Away     ATLCLE  102.000000  38.000000  87.0  11.000000   \n",
      "\n",
      "        FG3A        FTM        FTA  ...  FG_PCT_DIFF  FG3_PCT_DIFF  \\\n",
      "0  33.000000  17.500000  19.500000  ...     0.087751      0.171717   \n",
      "1  39.250000  11.750000  14.750000  ...     0.076186      0.086552   \n",
      "2  28.666667  25.333333  29.333333  ...     0.021847      0.032697   \n",
      "3  30.500000  14.500000  19.000000  ...    -0.046815     -0.050946   \n",
      "4  34.000000  15.000000  17.000000  ...     0.163218      0.202786   \n",
      "\n",
      "   FT_PCT_DIFF  TS%_DIFF  eFG%_DIFF  AST%_DIFF  ORtg_DIFF  PER%_DIFF  \\\n",
      "0    -0.073906  0.101770   0.120709  12.929062  11.108531  16.096461   \n",
      "1    -0.051156  0.093115   0.102684   8.212849  10.528649  14.800375   \n",
      "2    -0.128342  0.021669   0.051509   8.646982  -1.178508   9.553121   \n",
      "3    -0.026316 -0.055907  -0.056382  -5.326723   1.400965   6.773441   \n",
      "4    -0.012788  0.171636   0.171429   6.699507  17.089009   3.744821   \n",
      "\n",
      "   ORtg_Oliver_DIFF  DRtg_Oliver_DIFF  \n",
      "0          2.115378         10.628392  \n",
      "1          4.764998         10.655872  \n",
      "2          7.101445         -1.908589  \n",
      "3        -11.613594          1.294535  \n",
      "4          3.336355         15.302338  \n",
      "\n",
      "[5 rows x 70 columns]\n",
      "1722\n",
      "(22, 76)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"upcoming games= \",upcoming_games.head())\n",
    "print(len(upcoming_games))\n",
    "print(\"future_season_data\",future_season_data_stats.head())\n",
    "print(len(future_season_data_stats))\n",
    "# Merge final_data with future_season_data_stats on TEAM_ID and Home_Away because we want to see the averages by home and away attached for the models\n",
    "combined_data = pd.merge(upcoming_games, future_season_data_stats, on=['TEAM_ID', 'Home_Away', 'MATCHUP_ID'], how='left') #, 'MATCHUP'\n",
    "#print(combined_data.head())\n",
    "\n",
    "#count nan values\n",
    "#print(combined_data.isnull().sum())\n",
    "\n",
    "\n",
    "#view the team_id columns that have nan values\n",
    "#print(combined_data[combined_data['FG3A'].isnull()])\n",
    "\n",
    "# drop  Home_Away_x, MATCHUP_x, TEAM_ABBREVIATION_x and change any columns that end with _y to not have _y at the end\n",
    "#combined_data = combined_data.rename(columns={'Home_Away_y': 'Home_Away', 'MATCHUP_y': 'MATCHUP'})\n",
    "\n",
    "# drop the team_abbreviaton column\n",
    "combined_data.drop(['TEAM_ABBREVIATION'], axis=1, inplace=True)\n",
    "#print(combined_data.head())\n",
    "\n",
    "# matchup unique values\n",
    "#print(combined_data['MATCHUP'].unique())\n",
    "#drop matchup\n",
    "combined_data.drop(['MATCHUP'], axis=1, inplace=True)\n",
    "\n",
    "#print length of combined_data\n",
    "#print(len(combined_data))\n",
    "\n",
    "feature_order = ['PTS_PER_MIN', 'PTS_DIFF', 'PTS_PER_MIN_DIFF','TEAM_ID', 'TEAM_ID_OPP', 'FG_PCT', 'FG3_PCT', 'FT_PCT',\n",
    "                  'PLUS_MINUS', 'Home_Away', 'MATCHUP_ID',# 'FG_PCT_OPP', 'FG3_PCT_OPP',  'SEASON_ID', 'GAME_ID'\n",
    "                   'TS%', 'ORtg', 'PER%', 'eFG%', 'AST%', #'FT_PCT_OPP', 'PLUS_MINUS_OPP','TS%_OPP', 'eFG%_OPP', 'AST%_OPP', , 'MATCHUP'\n",
    "                  'YEAR', 'MONTH', 'DAY', #'DRtg', 'DPER%',\n",
    "                 'FG_PCT_DIFF','FG3_PCT_DIFF','FT_PCT_DIFF','TS%_DIFF','eFG%_DIFF','AST%_DIFF','ORtg_DIFF','PER%_DIFF'] #, 'MATCHUP'\n",
    "\n",
    "categorical_features = [ 'TEAM_ID', 'TEAM_ID_OPP', 'Home_Away', 'MATCHUP_ID'] \n",
    "\n",
    "# Reorder columns in the new_data DataFrame\n",
    "#combined_data_ordered = combined_data[feature_order]\n",
    "#print(combined_data.head())\n",
    "\n",
    "#filter for only today's games\n",
    "today = pd.Timestamp.today()\n",
    "combined_data = combined_data[combined_data['YEAR'] == today.year]\n",
    "combined_data = combined_data[combined_data['MONTH'] == today.month]\n",
    "combined_data = combined_data[combined_data['DAY'] == today.day]\n",
    "print(combined_data.shape)\n",
    "#print(combined_data.columns)\n",
    "\n",
    "# Write the data to a CSV file\n",
    "combined_data.to_csv(r'C:\\Users\\ghadf\\OneDrive\\Desktop\\Data Analytics\\Python\\ML\\nba_w_l_prediction_models\\nba_analysis\\data\\23_24_season_games_clean.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
